{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swlee23/Deep-Learning-Time-Series-Anomaly-Detection/blob/5-24_sCurr/DeepAnT_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJssM9Hd_rHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Things to be included\n",
        "# 1. visualization tools for optimization\n",
        "# 2. visualization tools for plotting actual and predicted sequence, and anomaly points\n",
        "# 3. Computation cost calculation\n",
        "# 4. Data of approximately 50~60 days required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60oNtF4FWakJ",
        "colab_type": "code",
        "outputId": "85e13483-9972-402a-e4f0-50bf6ca87e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import random\n",
        "from random import randint\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates\n",
        "from  matplotlib.dates import date2num\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1LKB0GwtQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpCyEz7QqJiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                       \"\"\"Anomaly detector\"\"\"\n",
        "def anomaly_detector(prediction_seq, ground_truth_seq):\n",
        "    # calculate Euclidean between actual seq and predicted seq\n",
        "    dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
        "    if (dist > anm_det_thr):\n",
        "        return true  # anomaly\n",
        "    else:\n",
        "        return false # normal "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCvn51nkpuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "              \"\"\"Hyperparameters\"\"\"\n",
        "w = 40                   # History window (number of time stamps taken into account) \n",
        "                         # i.e., filter(kernel) size       \n",
        "p_w = 6                  # Prediction window (number of time stampes required to be \n",
        "                         # predicted)\n",
        "n_features = 1           # Univariate time series\n",
        "\n",
        "kernel_size = 2          # Size of filter in conv layers\n",
        "num_filt_1 = 32          # Number of filters in first conv layer\n",
        "num_filt_2 = 32          # Number of filters in second conv layer\n",
        "num_nrn_dl = 40          # Number of neurons in dense layer\n",
        "num_nrn_ol = p_w         # Number of neurons in output layer\n",
        "\n",
        "conv_strides = 1\n",
        "pool_size_1 = 2          # Length of window of pooling layer 1\n",
        "pool_size_2 = 2          # Length of window of pooling layer 2\n",
        "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
        "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
        "\n",
        "epochs = 500\n",
        "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
        "learning_rate = 2e-5  \n",
        "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM-3LC6gd5kM",
        "colab_type": "code",
        "outputId": "8dc38d9b-c083-4cd1-a11c-725093e87e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "               \"\"\"Data loading (S current)\"\"\"\n",
        "df_Scurr = pd.read_csv('https://raw.githubusercontent.com/swlee23/Deep-Learning-Time-Series-Anomaly-Detection/master/data/HisItemCurrSMinute.csv')\n",
        "df_Scurr = df_Scurr.fillna(0)\n",
        "df_Scurr[\"DataSavedTime\"] = pd.to_datetime(df_Scurr[\"DataSavedTime\"])\n",
        "df_Scurr[\"DataSavedTime\"] = matplotlib.dates.date2num(df_Scurr[\"DataSavedTime\"])\n",
        "plt.xticks(rotation=70)\n",
        "plt.plot_date(x=df_Scurr[\"DataSavedTime\"], y=df_Scurr['Item001'], \n",
        "              linestyle='solid', marker='None')\n",
        "plt.title('s current')\n",
        "plt.ylabel('current value')\n",
        "plt.xlabel('time')\n",
        "plt.legend(['Item001'], loc='upper right')\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
            "\n",
            "To register the converters:\n",
            "\t>>> from pandas.plotting import register_matplotlib_converters\n",
            "\t>>> register_matplotlib_converters()\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE6CAYAAAAV5um7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 7200x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQsOxuDCIGpQ",
        "colab_type": "code",
        "outputId": "eabd32fa-75f1-41b2-adac-2547840819d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "              \"\"\"Data preprocessing\"\"\"\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + w\n",
        "\t\tout_end_ix = end_ix + p_w\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# remove zero values\n",
        "df_Scurr = df_Scurr[df_Scurr['Item001'] != 0]\n",
        "plt.xticks(rotation=70)\n",
        "plt.plot_date(x=df_Scurr[\"DataSavedTime\"], y=df_Scurr['Item001'], \n",
        "              linestyle='solid', marker='None')\n",
        "plt.title('s current')\n",
        "plt.ylabel('current value')\n",
        "plt.xlabel('time')\n",
        "plt.legend(['Item001'], loc='upper right')\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.show()\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = list(df_Scurr['Item001'])\n",
        "\n",
        "# split into samples\n",
        "batch_sample, batch_label = split_sequence(raw_seq)\n",
        "\n",
        "# summarize the data\n",
        "# for i in range(5):\n",
        "# \tprint(X[i], Y[i])\n",
        "  \n",
        "# 2. reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "\n",
        "# need to convert batch into 3D tensor of the form [batch_size, input_seq_len, n_features]\n",
        "batch_sample = batch_sample.reshape((batch_sample.shape[0], batch_sample.shape[1], n_features))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAE6CAYAAAAFqmUiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCeT/AUyYhuG+46H8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 7200x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLBqHZLmomSD",
        "colab_type": "code",
        "outputId": "27d22ddd-efaa-4430-f8bb-f378a999f3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "              \"\"\"Generate model for predictor\"\"\"\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer #1\n",
        "# Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
        "# Padding is added to preserve width.\n",
        "# Input Tensor Shape: [batch_size, w, 1] / batch_size = len(batch_sample)\n",
        "# Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
        "model.add(Conv1D(filters=num_filt_1,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 input_shape=(w, n_features)))\n",
        "\n",
        "# Pooling Layer #1\n",
        "# First max pooling layer with a filter of length 2 and stride of 2\n",
        "# Input Tensor Shape: [batch_size, w, num_filt_1]\n",
        "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1]\n",
        "\n",
        "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
        "                    #  strides=pool_strides_1, \n",
        "                    #  padding='valid'))\n",
        "\n",
        "# Convolutional Layer #2\n",
        "# Computes 64 features using a 5x5 filter.\n",
        "# Padding is added to preserve width and height.\n",
        "# Input Tensor Shape: [batch_size, 0.5 * w, 32]\n",
        "# Output Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
        "model.add(Conv1D(filters=num_filt_2,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu'))\n",
        "\n",
        "# Max Pooling Layer #2\n",
        "# Second max pooling layer with a 2x2 filter and stride of 2\n",
        "# Input Tensor Shape: [batch_size, 0.5 * w, num_filt_1 * num_filt_2]\n",
        "# Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
        "                    #  strides=pool_strides_2, \n",
        "                    #  padding='valid'\n",
        "          \n",
        "# Flatten tensor into a batch of vectors\n",
        "# Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "# Output Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer (Output layer)\n",
        "# Densely connected layer with 1024 neurons\n",
        "# Input Tensor Shape: [batch_size, 0.25 * w * num_filt_1 * num_filt_2]\n",
        "# Output Tensor Shape: [batch_size, 1024]\n",
        "model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
        "\n",
        "# Dropout\n",
        "# Prevents overfitting in deep neural networks\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "# Output layer\n",
        "# Input Tensor Shape: [batch_size, 1024]\n",
        "# Output Tensor Shape: [batch_size, p_w]\n",
        "model.add(Dense(units=num_nrn_ol))\n",
        "\n",
        "# Summarize model structure\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 08:50:15.200042 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0704 08:50:15.245979 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0704 08:50:15.253892 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0704 08:50:15.309787 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0704 08:50:15.369998 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0704 08:50:15.383294 140518448625536 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 39, 32)            96        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 19, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 18, 32)            2080      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 9, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                11560     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 246       \n",
            "=================================================================\n",
            "Total params: 13,982\n",
            "Trainable params: 13,982\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K76R-2HPajxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "31dbaa25-b1c7-4492-9b6e-11ba81da9261"
      },
      "source": [
        "                 '''configure model'''\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mean_absolute_error')\n",
        "\n",
        "# sgd = keras.optimizers.SGD(lr=learning_rate, \n",
        "#                          decay=1e-6, \n",
        "#                          momentum=0.9, \n",
        "#                          nesterov=True)\n",
        "# model.compile(optimizer='sgd', \n",
        "#               loss='mean_absolute_error', \n",
        "#               metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 08:50:15.432543 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO8EMSBaMZ8K",
        "colab_type": "code",
        "outputId": "ef1ccf46-b11a-4e14-ec12-baadfaeb4ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "                    '''Training'''\n",
        "model_fit = model.fit(batch_sample,\n",
        "                      batch_label,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 08:50:15.832987 140518448625536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "710/710 [==============================] - 1s 1ms/step - loss: 2.0104\n",
            "Epoch 2/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 1.1009\n",
            "Epoch 3/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.9597\n",
            "Epoch 4/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.8924\n",
            "Epoch 5/500\n",
            "710/710 [==============================] - 0s 131us/step - loss: 0.8673\n",
            "Epoch 6/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.8255\n",
            "Epoch 7/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.8075\n",
            "Epoch 8/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.7460\n",
            "Epoch 9/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.7588\n",
            "Epoch 10/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.7180\n",
            "Epoch 11/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.7103\n",
            "Epoch 12/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.6884\n",
            "Epoch 13/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.6917\n",
            "Epoch 14/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.6673\n",
            "Epoch 15/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.6532\n",
            "Epoch 16/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.6573\n",
            "Epoch 17/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.6364\n",
            "Epoch 18/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.6107\n",
            "Epoch 19/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.6005\n",
            "Epoch 20/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.6011\n",
            "Epoch 21/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.6071\n",
            "Epoch 22/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.6009\n",
            "Epoch 23/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.5640\n",
            "Epoch 24/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.5810\n",
            "Epoch 25/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.5869\n",
            "Epoch 26/500\n",
            "710/710 [==============================] - 0s 127us/step - loss: 0.5653\n",
            "Epoch 27/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.5797\n",
            "Epoch 28/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.5622\n",
            "Epoch 29/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.5644\n",
            "Epoch 30/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.5428\n",
            "Epoch 31/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.5543\n",
            "Epoch 32/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.5413\n",
            "Epoch 33/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.5332\n",
            "Epoch 34/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.5159\n",
            "Epoch 35/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.5165\n",
            "Epoch 36/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.5232\n",
            "Epoch 37/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.5127\n",
            "Epoch 38/500\n",
            "710/710 [==============================] - 0s 129us/step - loss: 0.5189\n",
            "Epoch 39/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.5333\n",
            "Epoch 40/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.5316\n",
            "Epoch 41/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.5107\n",
            "Epoch 42/500\n",
            "710/710 [==============================] - 0s 130us/step - loss: 0.5105\n",
            "Epoch 43/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.5026\n",
            "Epoch 44/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.4722\n",
            "Epoch 45/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.4917\n",
            "Epoch 46/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.4789\n",
            "Epoch 47/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4636\n",
            "Epoch 48/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.4983\n",
            "Epoch 49/500\n",
            "710/710 [==============================] - 0s 127us/step - loss: 0.5149\n",
            "Epoch 50/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.4946\n",
            "Epoch 51/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4858\n",
            "Epoch 52/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.4565\n",
            "Epoch 53/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.4417\n",
            "Epoch 54/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.4660\n",
            "Epoch 55/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.4588\n",
            "Epoch 56/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.4601\n",
            "Epoch 57/500\n",
            "710/710 [==============================] - 0s 131us/step - loss: 0.4569\n",
            "Epoch 58/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.4605\n",
            "Epoch 59/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.4434\n",
            "Epoch 60/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4271\n",
            "Epoch 61/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4407\n",
            "Epoch 62/500\n",
            "710/710 [==============================] - 0s 129us/step - loss: 0.4238\n",
            "Epoch 63/500\n",
            "710/710 [==============================] - 0s 144us/step - loss: 0.4472\n",
            "Epoch 64/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.4602\n",
            "Epoch 65/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.4265\n",
            "Epoch 66/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4575\n",
            "Epoch 67/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.4170\n",
            "Epoch 68/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.4436\n",
            "Epoch 69/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.4285\n",
            "Epoch 70/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4082\n",
            "Epoch 71/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.4121\n",
            "Epoch 72/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.4092\n",
            "Epoch 73/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.4162\n",
            "Epoch 74/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.3843\n",
            "Epoch 75/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.3918\n",
            "Epoch 76/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.3939\n",
            "Epoch 77/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.3719\n",
            "Epoch 78/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.3970\n",
            "Epoch 79/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.3814\n",
            "Epoch 80/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.3666\n",
            "Epoch 81/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.3793\n",
            "Epoch 82/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.3608\n",
            "Epoch 83/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.3642\n",
            "Epoch 84/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.3507\n",
            "Epoch 85/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.3629\n",
            "Epoch 86/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3621\n",
            "Epoch 87/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.3689\n",
            "Epoch 88/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3515\n",
            "Epoch 89/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.3391\n",
            "Epoch 90/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.3265\n",
            "Epoch 91/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.3505\n",
            "Epoch 92/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.3439\n",
            "Epoch 93/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3296\n",
            "Epoch 94/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3435\n",
            "Epoch 95/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.3330\n",
            "Epoch 96/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.3327\n",
            "Epoch 97/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.3257\n",
            "Epoch 98/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3170\n",
            "Epoch 99/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.3105\n",
            "Epoch 100/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.3212\n",
            "Epoch 101/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.2983\n",
            "Epoch 102/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.3101\n",
            "Epoch 103/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.2976\n",
            "Epoch 104/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.3047\n",
            "Epoch 105/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.2939\n",
            "Epoch 106/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.2998\n",
            "Epoch 107/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.2850\n",
            "Epoch 108/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2814\n",
            "Epoch 109/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.2888\n",
            "Epoch 110/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2917\n",
            "Epoch 111/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.2886\n",
            "Epoch 112/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.2735\n",
            "Epoch 113/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.2674\n",
            "Epoch 114/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.2626\n",
            "Epoch 115/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.2840\n",
            "Epoch 116/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2623\n",
            "Epoch 117/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2637\n",
            "Epoch 118/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.2570\n",
            "Epoch 119/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2474\n",
            "Epoch 120/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.2468\n",
            "Epoch 121/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.2382\n",
            "Epoch 122/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.2428\n",
            "Epoch 123/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2400\n",
            "Epoch 124/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.2343\n",
            "Epoch 125/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.2328\n",
            "Epoch 126/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2331\n",
            "Epoch 127/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.2265\n",
            "Epoch 128/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.2247\n",
            "Epoch 129/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.2227\n",
            "Epoch 130/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.2169\n",
            "Epoch 131/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.2156\n",
            "Epoch 132/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.2074\n",
            "Epoch 133/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.2070\n",
            "Epoch 134/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.2030\n",
            "Epoch 135/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.2065\n",
            "Epoch 136/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.1925\n",
            "Epoch 137/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1930\n",
            "Epoch 138/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.1867\n",
            "Epoch 139/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.1990\n",
            "Epoch 140/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.1834\n",
            "Epoch 141/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.1797\n",
            "Epoch 142/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.1851\n",
            "Epoch 143/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.1791\n",
            "Epoch 144/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.1847\n",
            "Epoch 145/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.1787\n",
            "Epoch 146/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.1718\n",
            "Epoch 147/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.1684\n",
            "Epoch 148/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1719\n",
            "Epoch 149/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.1656\n",
            "Epoch 150/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.1600\n",
            "Epoch 151/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1598\n",
            "Epoch 152/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1576\n",
            "Epoch 153/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.1534\n",
            "Epoch 154/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.1557\n",
            "Epoch 155/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.1429\n",
            "Epoch 156/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.1474\n",
            "Epoch 157/500\n",
            "710/710 [==============================] - 0s 129us/step - loss: 0.1419\n",
            "Epoch 158/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.1412\n",
            "Epoch 159/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.1357\n",
            "Epoch 160/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.1341\n",
            "Epoch 161/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.1362\n",
            "Epoch 162/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.1364\n",
            "Epoch 163/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1292\n",
            "Epoch 164/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.1291\n",
            "Epoch 165/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.1268\n",
            "Epoch 166/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.1233\n",
            "Epoch 167/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.1217\n",
            "Epoch 168/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.1211\n",
            "Epoch 169/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.1191\n",
            "Epoch 170/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.1175\n",
            "Epoch 171/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.1147\n",
            "Epoch 172/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.1137\n",
            "Epoch 173/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.1112\n",
            "Epoch 174/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.1086\n",
            "Epoch 175/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.1110\n",
            "Epoch 176/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.1087\n",
            "Epoch 177/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.1062\n",
            "Epoch 178/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.1051\n",
            "Epoch 179/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.1066\n",
            "Epoch 180/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1027\n",
            "Epoch 181/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1034\n",
            "Epoch 182/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.1028\n",
            "Epoch 183/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.1010\n",
            "Epoch 184/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0981\n",
            "Epoch 185/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0996\n",
            "Epoch 186/500\n",
            "710/710 [==============================] - 0s 131us/step - loss: 0.0986\n",
            "Epoch 187/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.0991\n",
            "Epoch 188/500\n",
            "710/710 [==============================] - 0s 147us/step - loss: 0.0977\n",
            "Epoch 189/500\n",
            "710/710 [==============================] - 0s 130us/step - loss: 0.0963\n",
            "Epoch 190/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.0956\n",
            "Epoch 191/500\n",
            "710/710 [==============================] - 0s 129us/step - loss: 0.0950\n",
            "Epoch 192/500\n",
            "710/710 [==============================] - 0s 133us/step - loss: 0.0947\n",
            "Epoch 193/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0945\n",
            "Epoch 194/500\n",
            "710/710 [==============================] - 0s 136us/step - loss: 0.0943\n",
            "Epoch 195/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0949\n",
            "Epoch 196/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0925\n",
            "Epoch 197/500\n",
            "710/710 [==============================] - 0s 130us/step - loss: 0.0932\n",
            "Epoch 198/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.0926\n",
            "Epoch 199/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.0924\n",
            "Epoch 200/500\n",
            "710/710 [==============================] - 0s 133us/step - loss: 0.0920\n",
            "Epoch 201/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0916\n",
            "Epoch 202/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0920\n",
            "Epoch 203/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.0914\n",
            "Epoch 204/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0910\n",
            "Epoch 205/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.0911\n",
            "Epoch 206/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0907\n",
            "Epoch 207/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0905\n",
            "Epoch 208/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0908\n",
            "Epoch 209/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.0904\n",
            "Epoch 210/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0901\n",
            "Epoch 211/500\n",
            "710/710 [==============================] - 0s 129us/step - loss: 0.0912\n",
            "Epoch 212/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0905\n",
            "Epoch 213/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0895\n",
            "Epoch 214/500\n",
            "710/710 [==============================] - 0s 136us/step - loss: 0.0899\n",
            "Epoch 215/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0898\n",
            "Epoch 216/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0894\n",
            "Epoch 217/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0898\n",
            "Epoch 218/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0895\n",
            "Epoch 219/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0894\n",
            "Epoch 220/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0889\n",
            "Epoch 221/500\n",
            "710/710 [==============================] - 0s 104us/step - loss: 0.0889\n",
            "Epoch 222/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0891\n",
            "Epoch 223/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0893\n",
            "Epoch 224/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0885\n",
            "Epoch 225/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0887\n",
            "Epoch 226/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0881\n",
            "Epoch 227/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0885\n",
            "Epoch 228/500\n",
            "710/710 [==============================] - 0s 104us/step - loss: 0.0891\n",
            "Epoch 229/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0888\n",
            "Epoch 230/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0883\n",
            "Epoch 231/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0883\n",
            "Epoch 232/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0883\n",
            "Epoch 233/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0882\n",
            "Epoch 234/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0881\n",
            "Epoch 235/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0884\n",
            "Epoch 236/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0879\n",
            "Epoch 237/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0879\n",
            "Epoch 238/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0879\n",
            "Epoch 239/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0877\n",
            "Epoch 240/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.0879\n",
            "Epoch 241/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0879\n",
            "Epoch 242/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0881\n",
            "Epoch 243/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0879\n",
            "Epoch 244/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0879\n",
            "Epoch 245/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0873\n",
            "Epoch 246/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0877\n",
            "Epoch 247/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0876\n",
            "Epoch 248/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0873\n",
            "Epoch 249/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0876\n",
            "Epoch 250/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0876\n",
            "Epoch 251/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0875\n",
            "Epoch 252/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0876\n",
            "Epoch 253/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0872\n",
            "Epoch 254/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0873\n",
            "Epoch 255/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0871\n",
            "Epoch 256/500\n",
            "710/710 [==============================] - 0s 103us/step - loss: 0.0875\n",
            "Epoch 257/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0871\n",
            "Epoch 258/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0871\n",
            "Epoch 259/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0872\n",
            "Epoch 260/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0870\n",
            "Epoch 261/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0871\n",
            "Epoch 262/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0872\n",
            "Epoch 263/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0873\n",
            "Epoch 264/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0869\n",
            "Epoch 265/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0872\n",
            "Epoch 266/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.0872\n",
            "Epoch 267/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0872\n",
            "Epoch 268/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0869\n",
            "Epoch 269/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0872\n",
            "Epoch 270/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0871\n",
            "Epoch 271/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0866\n",
            "Epoch 272/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0867\n",
            "Epoch 273/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0866\n",
            "Epoch 274/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0871\n",
            "Epoch 275/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0868\n",
            "Epoch 276/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0869\n",
            "Epoch 277/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0868\n",
            "Epoch 278/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0868\n",
            "Epoch 279/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0870\n",
            "Epoch 280/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0866\n",
            "Epoch 281/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0868\n",
            "Epoch 282/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0867\n",
            "Epoch 283/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0866\n",
            "Epoch 284/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0868\n",
            "Epoch 285/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0865\n",
            "Epoch 286/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0868\n",
            "Epoch 287/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0869\n",
            "Epoch 288/500\n",
            "710/710 [==============================] - 0s 124us/step - loss: 0.0866\n",
            "Epoch 289/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0862\n",
            "Epoch 290/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0864\n",
            "Epoch 291/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0866\n",
            "Epoch 292/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0864\n",
            "Epoch 293/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0862\n",
            "Epoch 294/500\n",
            "710/710 [==============================] - 0s 128us/step - loss: 0.0863\n",
            "Epoch 295/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0860\n",
            "Epoch 296/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0861\n",
            "Epoch 297/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0863\n",
            "Epoch 298/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0863\n",
            "Epoch 299/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0863\n",
            "Epoch 300/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0861\n",
            "Epoch 301/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0863\n",
            "Epoch 302/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0862\n",
            "Epoch 303/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0860\n",
            "Epoch 304/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0866\n",
            "Epoch 305/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0861\n",
            "Epoch 306/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0862\n",
            "Epoch 307/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0860\n",
            "Epoch 308/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0861\n",
            "Epoch 309/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0862\n",
            "Epoch 310/500\n",
            "710/710 [==============================] - 0s 103us/step - loss: 0.0859\n",
            "Epoch 311/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0861\n",
            "Epoch 312/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0862\n",
            "Epoch 313/500\n",
            "710/710 [==============================] - 0s 145us/step - loss: 0.0858\n",
            "Epoch 314/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0856\n",
            "Epoch 315/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0860\n",
            "Epoch 316/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0859\n",
            "Epoch 317/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0855\n",
            "Epoch 318/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0862\n",
            "Epoch 319/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0860\n",
            "Epoch 320/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0856\n",
            "Epoch 321/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0861\n",
            "Epoch 322/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0860\n",
            "Epoch 323/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0859\n",
            "Epoch 324/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0858\n",
            "Epoch 325/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0862\n",
            "Epoch 326/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0853\n",
            "Epoch 327/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0854\n",
            "Epoch 328/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0858\n",
            "Epoch 329/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0852\n",
            "Epoch 330/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0851\n",
            "Epoch 331/500\n",
            "710/710 [==============================] - 0s 102us/step - loss: 0.0854\n",
            "Epoch 332/500\n",
            "710/710 [==============================] - 0s 103us/step - loss: 0.0852\n",
            "Epoch 333/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0854\n",
            "Epoch 334/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0854\n",
            "Epoch 335/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0855\n",
            "Epoch 336/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0857\n",
            "Epoch 337/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0856\n",
            "Epoch 338/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0852\n",
            "Epoch 339/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0849\n",
            "Epoch 340/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0851\n",
            "Epoch 341/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0849\n",
            "Epoch 342/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0849\n",
            "Epoch 343/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0851\n",
            "Epoch 344/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0853\n",
            "Epoch 345/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0853\n",
            "Epoch 346/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0851\n",
            "Epoch 347/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0848\n",
            "Epoch 348/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0853\n",
            "Epoch 349/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0854\n",
            "Epoch 350/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0850\n",
            "Epoch 351/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0850\n",
            "Epoch 352/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0849\n",
            "Epoch 353/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0853\n",
            "Epoch 354/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0854\n",
            "Epoch 355/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0844\n",
            "Epoch 356/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.0850\n",
            "Epoch 357/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0847\n",
            "Epoch 358/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0844\n",
            "Epoch 359/500\n",
            "710/710 [==============================] - 0s 127us/step - loss: 0.0846\n",
            "Epoch 360/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0846\n",
            "Epoch 361/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0848\n",
            "Epoch 362/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0850\n",
            "Epoch 363/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0845\n",
            "Epoch 364/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0847\n",
            "Epoch 365/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0845\n",
            "Epoch 366/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0844\n",
            "Epoch 367/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0847\n",
            "Epoch 368/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0847\n",
            "Epoch 369/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0843\n",
            "Epoch 370/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0843\n",
            "Epoch 371/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0844\n",
            "Epoch 372/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0849\n",
            "Epoch 373/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0849\n",
            "Epoch 374/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0847\n",
            "Epoch 375/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0846\n",
            "Epoch 376/500\n",
            "710/710 [==============================] - 0s 104us/step - loss: 0.0847\n",
            "Epoch 377/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0846\n",
            "Epoch 378/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0845\n",
            "Epoch 379/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0846\n",
            "Epoch 380/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0841\n",
            "Epoch 381/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0847\n",
            "Epoch 382/500\n",
            "710/710 [==============================] - 0s 104us/step - loss: 0.0844\n",
            "Epoch 383/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0851\n",
            "Epoch 384/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0842\n",
            "Epoch 385/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0845\n",
            "Epoch 386/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0843\n",
            "Epoch 387/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0839\n",
            "Epoch 388/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0838\n",
            "Epoch 389/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0843\n",
            "Epoch 390/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0842\n",
            "Epoch 391/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0843\n",
            "Epoch 392/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0838\n",
            "Epoch 393/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0840\n",
            "Epoch 394/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0844\n",
            "Epoch 395/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0847\n",
            "Epoch 396/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0839\n",
            "Epoch 397/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0843\n",
            "Epoch 398/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0841\n",
            "Epoch 399/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0838\n",
            "Epoch 400/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0837\n",
            "Epoch 401/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0844\n",
            "Epoch 402/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.0840\n",
            "Epoch 403/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0837\n",
            "Epoch 404/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0843\n",
            "Epoch 405/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0839\n",
            "Epoch 406/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0841\n",
            "Epoch 407/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0842\n",
            "Epoch 408/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0842\n",
            "Epoch 409/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0842\n",
            "Epoch 410/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0840\n",
            "Epoch 411/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0834\n",
            "Epoch 412/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0837\n",
            "Epoch 413/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0837\n",
            "Epoch 414/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0834\n",
            "Epoch 415/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0839\n",
            "Epoch 416/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0833\n",
            "Epoch 417/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0832\n",
            "Epoch 418/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0829\n",
            "Epoch 419/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0835\n",
            "Epoch 420/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.0836\n",
            "Epoch 421/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0831\n",
            "Epoch 422/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0839\n",
            "Epoch 423/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0841\n",
            "Epoch 424/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0832\n",
            "Epoch 425/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0833\n",
            "Epoch 426/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0828\n",
            "Epoch 427/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0831\n",
            "Epoch 428/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0830\n",
            "Epoch 429/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0830\n",
            "Epoch 430/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0828\n",
            "Epoch 431/500\n",
            "710/710 [==============================] - 0s 103us/step - loss: 0.0829\n",
            "Epoch 432/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0831\n",
            "Epoch 433/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0836\n",
            "Epoch 434/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0835\n",
            "Epoch 435/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0840\n",
            "Epoch 436/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0834\n",
            "Epoch 437/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0831\n",
            "Epoch 438/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0833\n",
            "Epoch 439/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0834\n",
            "Epoch 440/500\n",
            "710/710 [==============================] - 0s 143us/step - loss: 0.0832\n",
            "Epoch 441/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0830\n",
            "Epoch 442/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0837\n",
            "Epoch 443/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0833\n",
            "Epoch 444/500\n",
            "710/710 [==============================] - 0s 109us/step - loss: 0.0836\n",
            "Epoch 445/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0837\n",
            "Epoch 446/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0832\n",
            "Epoch 447/500\n",
            "710/710 [==============================] - 0s 106us/step - loss: 0.0833\n",
            "Epoch 448/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0834\n",
            "Epoch 449/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0831\n",
            "Epoch 450/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0831\n",
            "Epoch 451/500\n",
            "710/710 [==============================] - 0s 120us/step - loss: 0.0840\n",
            "Epoch 452/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0835\n",
            "Epoch 453/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0821\n",
            "Epoch 454/500\n",
            "710/710 [==============================] - 0s 126us/step - loss: 0.0826\n",
            "Epoch 455/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0828\n",
            "Epoch 456/500\n",
            "710/710 [==============================] - 0s 116us/step - loss: 0.0831\n",
            "Epoch 457/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0830\n",
            "Epoch 458/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0824\n",
            "Epoch 459/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0825\n",
            "Epoch 460/500\n",
            "710/710 [==============================] - 0s 102us/step - loss: 0.0828\n",
            "Epoch 461/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0831\n",
            "Epoch 462/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0827\n",
            "Epoch 463/500\n",
            "710/710 [==============================] - 0s 101us/step - loss: 0.0827\n",
            "Epoch 464/500\n",
            "710/710 [==============================] - 0s 104us/step - loss: 0.0824\n",
            "Epoch 465/500\n",
            "710/710 [==============================] - 0s 114us/step - loss: 0.0837\n",
            "Epoch 466/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0829\n",
            "Epoch 467/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0829\n",
            "Epoch 468/500\n",
            "710/710 [==============================] - 0s 122us/step - loss: 0.0829\n",
            "Epoch 469/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0827\n",
            "Epoch 470/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0830\n",
            "Epoch 471/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0830\n",
            "Epoch 472/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0830\n",
            "Epoch 473/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0825\n",
            "Epoch 474/500\n",
            "710/710 [==============================] - 0s 110us/step - loss: 0.0819\n",
            "Epoch 475/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0825\n",
            "Epoch 476/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0830\n",
            "Epoch 477/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0826\n",
            "Epoch 478/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0828\n",
            "Epoch 479/500\n",
            "710/710 [==============================] - 0s 118us/step - loss: 0.0824\n",
            "Epoch 480/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0826\n",
            "Epoch 481/500\n",
            "710/710 [==============================] - 0s 107us/step - loss: 0.0824\n",
            "Epoch 482/500\n",
            "710/710 [==============================] - 0s 123us/step - loss: 0.0825\n",
            "Epoch 483/500\n",
            "710/710 [==============================] - 0s 113us/step - loss: 0.0826\n",
            "Epoch 484/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0831\n",
            "Epoch 485/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0816\n",
            "Epoch 486/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.0828\n",
            "Epoch 487/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0816\n",
            "Epoch 488/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0826\n",
            "Epoch 489/500\n",
            "710/710 [==============================] - 0s 125us/step - loss: 0.0821\n",
            "Epoch 490/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0822\n",
            "Epoch 491/500\n",
            "710/710 [==============================] - 0s 117us/step - loss: 0.0829\n",
            "Epoch 492/500\n",
            "710/710 [==============================] - 0s 121us/step - loss: 0.0818\n",
            "Epoch 493/500\n",
            "710/710 [==============================] - 0s 112us/step - loss: 0.0823\n",
            "Epoch 494/500\n",
            "710/710 [==============================] - 0s 119us/step - loss: 0.0821\n",
            "Epoch 495/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0822\n",
            "Epoch 496/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0820\n",
            "Epoch 497/500\n",
            "710/710 [==============================] - 0s 108us/step - loss: 0.0828\n",
            "Epoch 498/500\n",
            "710/710 [==============================] - 0s 115us/step - loss: 0.0824\n",
            "Epoch 499/500\n",
            "710/710 [==============================] - 0s 111us/step - loss: 0.0821\n",
            "Epoch 500/500\n",
            "710/710 [==============================] - 0s 105us/step - loss: 0.0827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URqDB0oxhX_X",
        "colab_type": "code",
        "outputId": "edc90153-bc59-4505-d702-a27fb070ea5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "                 \"\"\"Testing with random interval(DeepAnT)\"\"\"\n",
        "# Set number of test sequences \n",
        "n_test_seq = 1\n",
        "\n",
        "# Split a univariate sequence into samples\n",
        "def generate_test_batch(raw_seq, n_test_seq):\n",
        "  # Sample a portion of the raw_seq randomly\n",
        "    ran_ix = random.randint(0,len(raw_seq) - n_test_seq * w - n_test_seq * p_w)\n",
        "    raw_test_seq = array(raw_seq[ran_ix:ran_ix + n_test_seq * w +  n_test_seq * p_w])\n",
        "    batch_test_seq, batch_test_label = list(), list()\n",
        "    ix = ran_ix\n",
        "    for i in range(n_test_seq):\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x = raw_seq[ix : ix+w],\n",
        "        seq_y = raw_seq[ix+w : ix+w+p_w]\n",
        "        ix = ix+w+p_w\n",
        "        batch_test_seq.append(seq_x)\n",
        "        batch_test_label.append(seq_y)\n",
        "    return array(batch_test_seq), array(batch_test_label)\n",
        "\n",
        "raw_seq = list(df_Scurr['Item001'])\n",
        "batch_test_seq, batch_test_label = generate_test_batch(raw_seq, n_test_seq)\n",
        "batch_test_seq = batch_test_seq.reshape((batch_test_seq.shape[0], w, n_features))\n",
        "batch_test_label = batch_test_label.reshape((batch_test_label.shape[0], p_w))\n",
        "\n",
        "# Returns the loss value & metrics values for the model in test mode\n",
        "model.evaluate(x=batch_test_seq,\n",
        "               y=batch_test_label,\n",
        "               verbose=1) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 48ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08682743459939957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK0_Cq-Oh0tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "               \"\"\"Save Weights (DeepAnT)\"\"\"\n",
        "# save it to disk so we can load it back up anytime\n",
        "model.save_weights('05-24-sCurr_DeepAnT.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzknk4th9bU",
        "colab_type": "code",
        "outputId": "2dba5172-5ecf-437c-c0fa-f2bbbbaa6d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "            \"\"\"Predicting random intervals (DeepAnT)\"\"\"\n",
        "# Build model \n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=num_filt_1,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 input_shape=(w, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
        "model.add(Conv1D(filters=num_filt_2,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(units=num_nrn_ol))\n",
        "\n",
        "# Load the model's saved weights.\n",
        "model.save_weights('05-24-sCurr_DeepAnT.h5')  \n",
        "          \n",
        "# Sample a portion of the raw_seq randomly\n",
        "# 1. Choose \n",
        "raw_seq = list(df_Scurr['Item001'])\n",
        "ran_ix = random.randint(1,len(raw_seq) - w - p_w)\n",
        "input_seq = array(raw_seq[ran_ix : ran_ix + w])\n",
        "target_seq = array(raw_seq[ran_ix + w : ran_ix + w + p_w])\n",
        "input_seq = input_seq.reshape((1, w, n_features))\n",
        "\n",
        "# Predict the next time stampes of the sampled sequence\n",
        "yhat = model.predict(input_seq, verbose=1)\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(yhat)\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(target_seq) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 52ms/step\n",
            "[[ 0.46644378  0.00073365 -0.3285263   0.5135169   0.22978374 -0.30211395]]\n",
            "[2.81 2.97 2.8  2.84 2.89 2.8 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-oM2iL1gw4Q",
        "colab_type": "code",
        "outputId": "d0a2d37b-6ccf-4922-bb99-ee85facd5fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "            \"\"\"Predicting future sequence (DeepAnT)\"\"\"\n",
        "# Build model \n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=num_filt_1,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 input_shape=(w, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=pool_size_1)) \n",
        "model.add(Conv1D(filters=num_filt_2,\n",
        "                 kernel_size=kernel_size,\n",
        "                 strides=conv_strides,\n",
        "                 padding='valid',\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=pool_size_2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=num_nrn_dl, activation='relu')) \n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(units=num_nrn_ol))\n",
        "\n",
        "# Load the model's saved weights.\n",
        "model.save_weights('05-24-sCurr_DeepAnT.h5')  \n",
        "          \n",
        "    \n",
        "raw_seq = list(df_Scurr['Item001'])\n",
        "endix = len(raw_seq) - w - p_w\n",
        "input_seq = array(raw_seq[endix:endix+w])\n",
        "target_seq = array(raw_seq[endix+w:endix+w+p_w]) \n",
        "input_seq = input_seq.reshape((1, w, n_features))\n",
        "\n",
        "# Predict the next time stampes of the sampled sequence\n",
        "predicted_seq = model.predict(input_seq, verbose=1)\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(predicted_seq)\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(target_seq) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 54ms/step\n",
            "[[ 0.29133096  0.06170802  0.11865401  0.09314132 -0.01324761  0.48525414]]\n",
            "[2.89 2.9  2.75 2.87 2.85 2.84]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "664VO9gMmmFE",
        "colab_type": "code",
        "outputId": "8263bda7-8c2e-4564-9aa7-57938e8315dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "           '''Visualization of predicted time series'''\n",
        "in_seq = raw_seq[endix:endix+w]\n",
        "tar_seq = raw_seq[endix+w:endix+w+p_w]\n",
        "predicted_seq = predicted_seq.reshape((p_w))\n",
        "d = {'time': df_Scurr['DataSavedTime'][endix+w:endix+w+p_w], 'current': predicted_seq}\n",
        "df_Scurr_pre = pd.DataFrame(data=d)\n",
        "pre_seq = df_Scurr_pre['current']\n",
        "\n",
        "plt.xticks(rotation=70)\n",
        "plt.plot_date(x=df_Scurr['DataSavedTime'][endix:endix+w], y=in_seq, \n",
        "              linestyle='solid', marker='None')\n",
        "plt.plot_date(x=df_Scurr['DataSavedTime'][endix+w:endix+w+p_w], y=tar_seq, \n",
        "              linestyle='solid', marker='None')\n",
        "plt.plot_date(x=df_Scurr['DataSavedTime'][endix+w:endix+w+p_w], y=pre_seq, \n",
        "              linestyle='solid', marker='None')\n",
        "plt.title('s current')\n",
        "plt.ylabel('current value')\n",
        "plt.xlabel('time')\n",
        "plt.legend(['in_seq', 'tar_seq', 'predicted_seq'], loc='upper right')\n",
        "axes = plt.gca()\n",
        "# axes.set_xlim(df_Scurr['DataSavedTime'][endix],\n",
        "#               df_Scurr['DataSavedTime'][endix+w+p_w-1])\n",
        "plt.figure(figsize=(100,10))\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE5CAYAAACTcpsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nED9HkCXXhwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 7200x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2SqYbNoPXG",
        "colab_type": "code",
        "outputId": "9c1bf9a5-ccd0-4cf3-f9df-ba5c40aec1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Shallow CNN version  \n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "raw_seq = [-5, 5, -10, 10, -15, 15, -20, 20, -25]\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=1)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
        "yhat = model.predict(x_input, verbose=1)\n",
        "print(yhat)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 17.4091\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 425us/step - loss: 17.3047\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 657us/step - loss: 17.2060\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 442us/step - loss: 17.1055\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 17.0029\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 436us/step - loss: 16.9068\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 384us/step - loss: 16.8127\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 16.7241\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 390us/step - loss: 16.6311\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 754us/step - loss: 16.5434\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 915us/step - loss: 16.4576\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 671us/step - loss: 16.3701\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 752us/step - loss: 16.2826\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 560us/step - loss: 16.1926\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 586us/step - loss: 16.1008\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 437us/step - loss: 16.0075\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 439us/step - loss: 15.9140\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 339us/step - loss: 15.8191\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 445us/step - loss: 15.7209\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 438us/step - loss: 15.6192\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 564us/step - loss: 15.5165\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 440us/step - loss: 15.4174\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 490us/step - loss: 15.3151\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 459us/step - loss: 15.2077\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 420us/step - loss: 15.0991\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 444us/step - loss: 14.9866\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 451us/step - loss: 14.8696\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 526us/step - loss: 14.7490\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 502us/step - loss: 14.6267\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 467us/step - loss: 14.5020\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 583us/step - loss: 14.4559\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 526us/step - loss: 14.4139\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 483us/step - loss: 14.3438\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 457us/step - loss: 14.2485\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 476us/step - loss: 14.1406\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 595us/step - loss: 14.0278\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 556us/step - loss: 13.9592\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 525us/step - loss: 13.9081\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 465us/step - loss: 13.8422\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 746us/step - loss: 13.7624\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 459us/step - loss: 13.7652\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 660us/step - loss: 13.7727\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 464us/step - loss: 13.7642\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 406us/step - loss: 13.7270\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 479us/step - loss: 13.6476\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 484us/step - loss: 13.5715\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 436us/step - loss: 13.5087\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 682us/step - loss: 13.4957\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 323us/step - loss: 13.4951\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 493us/step - loss: 13.4751\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 515us/step - loss: 13.4313\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 460us/step - loss: 13.3942\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 673us/step - loss: 13.3560\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 693us/step - loss: 13.3004\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 434us/step - loss: 13.2399\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 689us/step - loss: 13.2453\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 954us/step - loss: 13.2034\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 666us/step - loss: 13.1426\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 664us/step - loss: 13.1231\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 604us/step - loss: 13.0836\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 622us/step - loss: 13.0437\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 540us/step - loss: 13.0036\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 545us/step - loss: 12.9812\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 849us/step - loss: 12.9600\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 753us/step - loss: 12.9205\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 549us/step - loss: 12.8798\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 826us/step - loss: 12.8504\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 585us/step - loss: 12.8171\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 648us/step - loss: 12.7641\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 595us/step - loss: 12.7508\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 689us/step - loss: 12.7237\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 712us/step - loss: 12.6831\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 966us/step - loss: 12.6400\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 781us/step - loss: 12.6009\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 634us/step - loss: 12.5496\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 885us/step - loss: 12.5156\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 666us/step - loss: 12.4684\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 764us/step - loss: 12.4481\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 965us/step - loss: 12.4151\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.3780\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 792us/step - loss: 12.3310\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 893us/step - loss: 12.2721\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 941us/step - loss: 12.2370\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 797us/step - loss: 12.2088\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 879us/step - loss: 12.1524\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 12.1249\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.0860\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 593us/step - loss: 12.0237\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 561us/step - loss: 12.0033\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 499us/step - loss: 12.0003\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 520us/step - loss: 11.9127\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 475us/step - loss: 11.8550\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 454us/step - loss: 11.8241\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 527us/step - loss: 11.7671\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 483us/step - loss: 11.7452\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 422us/step - loss: 11.6852\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 408us/step - loss: 11.6651\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 453us/step - loss: 11.6208\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 489us/step - loss: 11.5646\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 438us/step - loss: 11.5288\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 463us/step - loss: 11.4896\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 461us/step - loss: 11.4535\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 430us/step - loss: 11.4076\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 389us/step - loss: 11.3743\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 407us/step - loss: 11.3279\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 386us/step - loss: 11.2923\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 401us/step - loss: 11.2583\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 398us/step - loss: 11.2138\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 410us/step - loss: 11.1596\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 439us/step - loss: 11.1238\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 633us/step - loss: 11.0806\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 656us/step - loss: 11.0229\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 492us/step - loss: 10.9825\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 468us/step - loss: 10.9312\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 467us/step - loss: 10.8913\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 549us/step - loss: 10.8355\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 451us/step - loss: 10.8037\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 414us/step - loss: 10.7543\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 545us/step - loss: 10.6988\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 503us/step - loss: 10.6330\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 517us/step - loss: 10.6197\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 585us/step - loss: 10.5737\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 411us/step - loss: 10.4952\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 578us/step - loss: 10.4424\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 478us/step - loss: 10.4070\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 574us/step - loss: 10.3585\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 521us/step - loss: 10.2980\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 522us/step - loss: 10.2263\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 552us/step - loss: 10.1445\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 366us/step - loss: 10.0908\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 349us/step - loss: 10.0416\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 428us/step - loss: 9.9861\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 408us/step - loss: 9.9180\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 508us/step - loss: 9.8539\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 640us/step - loss: 9.7820\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 638us/step - loss: 9.7414\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 402us/step - loss: 9.6879\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 399us/step - loss: 9.6204\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 577us/step - loss: 9.5420\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 564us/step - loss: 9.4612\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 442us/step - loss: 9.3954\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 420us/step - loss: 9.3348\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 447us/step - loss: 9.2706\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 650us/step - loss: 9.1897\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 435us/step - loss: 9.1163\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 402us/step - loss: 9.0360\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 390us/step - loss: 8.9785\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 396us/step - loss: 8.9201\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 431us/step - loss: 8.8290\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 440us/step - loss: 8.7295\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 480us/step - loss: 8.7034\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 471us/step - loss: 8.6332\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 572us/step - loss: 8.5161\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 418us/step - loss: 8.4307\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 417us/step - loss: 8.3734\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 686us/step - loss: 8.2955\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 370us/step - loss: 8.1995\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 561us/step - loss: 8.0905\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 359us/step - loss: 7.9874\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 611us/step - loss: 7.9042\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 421us/step - loss: 7.8046\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 442us/step - loss: 7.7173\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 650us/step - loss: 7.6127\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 427us/step - loss: 7.5474\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 458us/step - loss: 7.4335\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 462us/step - loss: 7.3558\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 399us/step - loss: 7.2578\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 392us/step - loss: 7.1400\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 393us/step - loss: 7.0853\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 695us/step - loss: 6.9600\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 559us/step - loss: 6.8903\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 619us/step - loss: 6.7977\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 612us/step - loss: 6.6859\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 403us/step - loss: 6.5783\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 907us/step - loss: 6.4852\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 485us/step - loss: 6.4069\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 419us/step - loss: 6.2873\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 494us/step - loss: 6.1829\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 473us/step - loss: 6.0763\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 455us/step - loss: 5.9719\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 425us/step - loss: 5.8655\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 417us/step - loss: 5.7552\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 455us/step - loss: 5.6481\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 440us/step - loss: 5.5380\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 475us/step - loss: 5.4248\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 444us/step - loss: 5.3168\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 469us/step - loss: 5.1884\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 422us/step - loss: 5.0696\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 494us/step - loss: 4.9473\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 502us/step - loss: 4.8234\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 586us/step - loss: 4.6947\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 455us/step - loss: 4.5632\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 435us/step - loss: 4.4368\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 641us/step - loss: 4.3093\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 500us/step - loss: 4.1777\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 531us/step - loss: 4.0421\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 481us/step - loss: 3.9197\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 455us/step - loss: 3.8120\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 3.6821\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 517us/step - loss: 3.5890\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 698us/step - loss: 3.4197\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 3.3000\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 713us/step - loss: 3.1768\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 803us/step - loss: 3.0489\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 475us/step - loss: 2.9947\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 654us/step - loss: 2.9050\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 642us/step - loss: 2.8580\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 670us/step - loss: 2.8090\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 466us/step - loss: 2.7477\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 791us/step - loss: 2.7080\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 768us/step - loss: 2.6986\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 773us/step - loss: 2.6070\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 585us/step - loss: 2.5369\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 2.4932\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 768us/step - loss: 2.4360\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 851us/step - loss: 2.3935\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 710us/step - loss: 2.3929\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 719us/step - loss: 2.3749\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 809us/step - loss: 2.3271\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 761us/step - loss: 2.4504\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 707us/step - loss: 2.4275\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 2.4096\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 712us/step - loss: 2.4276\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 738us/step - loss: 2.3196\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 702us/step - loss: 2.2925\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 621us/step - loss: 2.3066\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 601us/step - loss: 2.3174\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 703us/step - loss: 2.2945\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 697us/step - loss: 2.2831\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 663us/step - loss: 2.2744\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 694us/step - loss: 2.2296\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 641us/step - loss: 2.2171\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 658us/step - loss: 2.2524\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 632us/step - loss: 2.1484\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 575us/step - loss: 2.1614\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 637us/step - loss: 2.1623\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 689us/step - loss: 2.1506\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 642us/step - loss: 2.1523\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 547us/step - loss: 2.1277\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 639us/step - loss: 2.1413\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 719us/step - loss: 2.1437\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 600us/step - loss: 2.1968\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 560us/step - loss: 2.1664\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 559us/step - loss: 2.2919\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 484us/step - loss: 2.1843\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 683us/step - loss: 2.2457\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 489us/step - loss: 2.1042\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 648us/step - loss: 2.1281\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 479us/step - loss: 2.0804\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 644us/step - loss: 2.0974\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 607us/step - loss: 2.0587\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 539us/step - loss: 2.1257\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 461us/step - loss: 2.0989\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 506us/step - loss: 2.0490\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 646us/step - loss: 2.0980\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 573us/step - loss: 2.0742\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 630us/step - loss: 2.0729\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 625us/step - loss: 2.0271\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 634us/step - loss: 2.0494\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 544us/step - loss: 2.0456\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 739us/step - loss: 2.1440\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 558us/step - loss: 2.1045\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 544us/step - loss: 2.0911\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 535us/step - loss: 2.0919\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 540us/step - loss: 2.0088\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 563us/step - loss: 1.9707\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 513us/step - loss: 2.1454\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 562us/step - loss: 2.1455\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 638us/step - loss: 2.0890\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 591us/step - loss: 2.0325\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 628us/step - loss: 2.0159\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 606us/step - loss: 2.0252\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 574us/step - loss: 2.0490\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 598us/step - loss: 2.0446\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 558us/step - loss: 2.0673\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 539us/step - loss: 1.9909\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 527us/step - loss: 2.1736\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 573us/step - loss: 2.2010\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 517us/step - loss: 1.9919\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 503us/step - loss: 2.2137\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 499us/step - loss: 2.3325\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 514us/step - loss: 2.2231\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 472us/step - loss: 2.1207\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 564us/step - loss: 2.2325\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 580us/step - loss: 2.0152\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 529us/step - loss: 1.9956\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 566us/step - loss: 2.0153\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 574us/step - loss: 2.1260\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 549us/step - loss: 2.2013\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 551us/step - loss: 2.1558\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 509us/step - loss: 2.0843\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 562us/step - loss: 2.0455\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 603us/step - loss: 2.0673\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 606us/step - loss: 2.1243\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 555us/step - loss: 1.9743\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 562us/step - loss: 2.1247\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 536us/step - loss: 2.2812\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 592us/step - loss: 2.2543\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 620us/step - loss: 2.1844\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 556us/step - loss: 2.1508\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 536us/step - loss: 2.2342\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 561us/step - loss: 1.9627\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 554us/step - loss: 2.0074\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 593us/step - loss: 1.9989\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 595us/step - loss: 2.0384\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 546us/step - loss: 2.1116\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 703us/step - loss: 2.0076\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 557us/step - loss: 2.0776\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 522us/step - loss: 2.0832\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9466\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 716us/step - loss: 2.0758\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 505us/step - loss: 2.0763\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 570us/step - loss: 2.0335\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 684us/step - loss: 2.1882\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 571us/step - loss: 2.1663\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 795us/step - loss: 1.9811\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 773us/step - loss: 2.0897\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 635us/step - loss: 2.1602\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 557us/step - loss: 2.0212\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 791us/step - loss: 2.0564\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 2.1498\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 553us/step - loss: 2.0556\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 1.9506\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 564us/step - loss: 2.2119\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 525us/step - loss: 2.0090\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 488us/step - loss: 2.0249\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 506us/step - loss: 2.1918\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 495us/step - loss: 2.1708\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 536us/step - loss: 1.9797\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 594us/step - loss: 2.1208\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 474us/step - loss: 2.3394\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 545us/step - loss: 2.0800\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 515us/step - loss: 2.0029\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 490us/step - loss: 2.1284\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 595us/step - loss: 2.0744\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 560us/step - loss: 1.9259\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 514us/step - loss: 2.1277\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 694us/step - loss: 2.2037\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 498us/step - loss: 1.9358\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 542us/step - loss: 2.1878\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 514us/step - loss: 2.3589\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 527us/step - loss: 2.3506\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 646us/step - loss: 2.1818\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 571us/step - loss: 1.9235\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 709us/step - loss: 2.2360\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 662us/step - loss: 2.2420\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 691us/step - loss: 1.9768\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 535us/step - loss: 2.1858\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 518us/step - loss: 2.3809\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 610us/step - loss: 2.4002\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 653us/step - loss: 2.2619\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 673us/step - loss: 2.0124\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 690us/step - loss: 2.1179\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 600us/step - loss: 2.2498\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 761us/step - loss: 2.2050\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 638us/step - loss: 1.9918\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 517us/step - loss: 2.0533\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 498us/step - loss: 2.1821\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 493us/step - loss: 2.1632\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 612us/step - loss: 2.1187\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 624us/step - loss: 2.0868\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 773us/step - loss: 2.0968\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 548us/step - loss: 2.0379\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 547us/step - loss: 1.9438\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 500us/step - loss: 2.0533\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 539us/step - loss: 2.0199\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 604us/step - loss: 2.0297\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 726us/step - loss: 2.0659\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 659us/step - loss: 2.0095\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 737us/step - loss: 1.9831\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 528us/step - loss: 1.9726\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 867us/step - loss: 1.9341\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 491us/step - loss: 1.9421\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 727us/step - loss: 2.0226\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 585us/step - loss: 1.9929\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 811us/step - loss: 2.0360\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 723us/step - loss: 2.0197\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 746us/step - loss: 1.9521\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 519us/step - loss: 1.9167\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 540us/step - loss: 1.9173\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 1.9341\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 556us/step - loss: 1.9205\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 557us/step - loss: 1.9491\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 553us/step - loss: 1.8997\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 526us/step - loss: 1.9046\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 583us/step - loss: 1.9024\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 544us/step - loss: 1.9032\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 510us/step - loss: 1.9071\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 733us/step - loss: 1.9393\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 712us/step - loss: 1.9601\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 1.9200\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 768us/step - loss: 1.9024\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 680us/step - loss: 1.8820\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 720us/step - loss: 1.8852\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 1.8747\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 798us/step - loss: 1.8808\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 530us/step - loss: 1.9308\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 587us/step - loss: 1.9545\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 530us/step - loss: 1.9171\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 696us/step - loss: 1.9246\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 622us/step - loss: 1.8935\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 675us/step - loss: 1.9661\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 523us/step - loss: 1.9831\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 726us/step - loss: 1.8870\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 668us/step - loss: 2.0288\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 710us/step - loss: 1.9482\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 619us/step - loss: 1.9566\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 646us/step - loss: 2.0091\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 634us/step - loss: 1.9103\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 768us/step - loss: 2.0254\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 745us/step - loss: 2.0860\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 760us/step - loss: 1.9828\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 720us/step - loss: 1.9304\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 726us/step - loss: 1.9886\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 441us/step - loss: 1.9227\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 638us/step - loss: 1.9136\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.8763\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 1.8589\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 492us/step - loss: 1.8769\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 480us/step - loss: 1.9089\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 466us/step - loss: 1.8853\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 500us/step - loss: 1.9159\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 494us/step - loss: 1.8642\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 380us/step - loss: 1.8547\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 472us/step - loss: 1.8632\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 448us/step - loss: 1.9019\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 481us/step - loss: 1.9094\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 550us/step - loss: 1.8604\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 414us/step - loss: 1.9548\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 580us/step - loss: 1.8413\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 983us/step - loss: 1.9914\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 430us/step - loss: 1.9940\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.9117\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 764us/step - loss: 1.9256\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 952us/step - loss: 1.8602\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 545us/step - loss: 1.8611\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.8874\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.9105\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 794us/step - loss: 1.9320\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.8996\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 613us/step - loss: 1.8762\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 688us/step - loss: 1.8438\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 597us/step - loss: 1.8622\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 830us/step - loss: 1.8522\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 577us/step - loss: 1.8650\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 616us/step - loss: 1.8452\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.8647\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.8375\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 658us/step - loss: 1.8552\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 671us/step - loss: 1.8923\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 1.9135\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 626us/step - loss: 1.8503\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 455us/step - loss: 2.0206\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 637us/step - loss: 1.9094\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.9397\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.9992\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 991us/step - loss: 1.9141\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 771us/step - loss: 1.9556\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 746us/step - loss: 2.0063\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.9039\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.9549\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 910us/step - loss: 2.0145\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 739us/step - loss: 1.9310\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 673us/step - loss: 1.8844\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 864us/step - loss: 1.8430\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 822us/step - loss: 1.8773\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 470us/step - loss: 1.8602\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 612us/step - loss: 1.8442\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 599us/step - loss: 1.8378\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 527us/step - loss: 1.8591\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 690us/step - loss: 1.8403\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 607us/step - loss: 1.9233\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 723us/step - loss: 1.9178\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 561us/step - loss: 1.8351\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 859us/step - loss: 2.0450\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 591us/step - loss: 1.9045\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 723us/step - loss: 1.9930\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 777us/step - loss: 2.1235\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 440us/step - loss: 2.1060\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 562us/step - loss: 1.9555\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 466us/step - loss: 1.9253\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 627us/step - loss: 2.0463\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 426us/step - loss: 1.8966\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 462us/step - loss: 1.9777\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 503us/step - loss: 2.0807\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 462us/step - loss: 2.0417\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 530us/step - loss: 1.8768\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 434us/step - loss: 2.0162\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 510us/step - loss: 2.2051\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 495us/step - loss: 1.9954\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 543us/step - loss: 1.8551\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 681us/step - loss: 1.9470\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 715us/step - loss: 1.8978\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 870us/step - loss: 1.8563\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 607us/step - loss: 1.8748\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 641us/step - loss: 1.8396\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 998us/step - loss: 1.8784\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 559us/step - loss: 1.8620\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 751us/step - loss: 1.8297\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 821us/step - loss: 1.8735\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "[[ 68.57659  -62.789745]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFv7f2x-euPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "               \"\"\"Save Weights (ShallowAnT)\"\"\"\n",
        "# save it to disk so we can load it back up anytime\n",
        "model.save_weights('sinwave_ShallowAnT_1.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}