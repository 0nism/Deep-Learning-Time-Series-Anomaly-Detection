{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swlee23/Deep-Learning-Time-Series-Anomaly-Detection/blob/master/DeepAnT_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJssM9Hd_rHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Things to be included\n",
        "# 0. preprocess segment for seq (raw -> input format)\n",
        "# 1. visualization tools for sgd\n",
        "# 2. visualization tools for plotting actual and predicted sequence, and anomaly points\n",
        "# 3. Implementation of unsupervised learning techniques\n",
        "# 4. GPU position check If the machine on which you train on has a GPU on 0,\n",
        "#    make sure to use 0 instead of 1. You can check that by running a simple \n",
        "#    command on your terminal: for example, nvidia-smi\n",
        "# 5. other optimizer such as adam is better?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60oNtF4FWakJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Activation\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1LKB0GwtQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCvn51nkpuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "              \"\"\"Hyperparameters\"\"\"\n",
        "\n",
        "w = 5                    # History window (length of chopped sequences) / kernel size       \n",
        "p_w = 1                  # Prediction window (number of time stampes required to be \n",
        "                         # predicted)\n",
        "\n",
        "num_filt_1 = 32          # Number of filters in first conv layer\n",
        "num_filt_2 = 32          # Number of filters in second conv layer\n",
        "num_nrn_dl = 40          # Number of neurons in dense layer\n",
        "num_nrn_ol = p_w         # Number of neurons in output layer\n",
        "\n",
        "conv_strides = 1\n",
        "pool_size_1 = 2          # Length of window of pooling layer 1\n",
        "pool_size_2 = 2          # Length of window of pooling layer 2\n",
        "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
        "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 30          # Daily current trend data for 1 month \n",
        "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
        "learning_rate = 2e-5  \n",
        "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKYzBd94KZFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                \"\"\"Data loading\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQsOxuDCIGpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c3e21ba9-6961-43eb-f701-2c6dc2a23d20"
      },
      "source": [
        "              \"\"\"Data preprocessing\"\"\"\n",
        "# 1. split a univariate sequence into samples\n",
        "def split_sequence(raw_seq, n_steps, prediction_seq_len):\n",
        "\tX, Y = list(), list()\n",
        "\tfor i in range(len(raw_seq)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(raw_seq)-prediction_seq_len:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = raw_seq[i:end_ix], raw_seq[end_ix:end_ix + prediction_seq_len]\n",
        "\t\tX.append(seq_x)\n",
        "\t\tY.append(seq_y)\n",
        "\treturn np.array(X), np.array(Y)\n",
        "\n",
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = w\n",
        "# choose length of prediction sequence\n",
        "prediction_seq_len = p_w\n",
        "# split into samples\n",
        "X, Y = split_sequence(raw_seq, n_steps, prediction_seq_len)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "\tprint(X[i], Y[i])\n",
        "  \n",
        "\n",
        "  \n",
        "# 2. reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 30 40 50] [60]\n",
            "[20 30 40 50 60] [70]\n",
            "[30 40 50 60 70] [80]\n",
            "[40 50 60 70 80] [90]\n",
            "4 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLBqHZLmomSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "              \"\"\"Generate model for predictor\"\"\"\n",
        "def predictor_model_generator():\n",
        "  model = Sequential()\n",
        "  # Input Layer\n",
        "  # Reshape X to 3-D tensor: [batch_size, width, channels]\n",
        "  # MNIST images are 28x28 pixels, and have one color channel\n",
        "\n",
        "\n",
        "  # Convolutional Layer #1\n",
        "  # Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
        "  # Padding is added to preserve width.\n",
        "  # Input Tensor Shape: [batch_size, input_seq_len, 1]\n",
        "  # Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
        "  model.add(Conv1D(filters=num_filt_1,\n",
        "                   kernel_size=w,\n",
        "                   strides=conv_strides,\n",
        "                   padding='valid',\n",
        "                   activation='relu',\n",
        "                   input_shape=(w, 1)))\n",
        "\n",
        "  # Pooling Layer #1\n",
        "  # First max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, w, num_filt_1]\n",
        "  # Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1]\n",
        "  \n",
        "  model.add(MaxPooling1D(pool_size=pool_size_1, \n",
        "                         strides=pool_strides_1, \n",
        "                         padding='valid'))\n",
        "\n",
        "  # Convolutional Layer #2\n",
        "  # Computes 64 features using a 5x5 filter.\n",
        "  # Padding is added to preserve width and height.\n",
        "  # Input Tensor Shape: [batch_size, 0.25 * w, 32]\n",
        "  # Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "  model.add(Conv1D(filters=num_filt_2,\n",
        "                   kernel_size=w,\n",
        "                   strides=conv_strides,\n",
        "                   padding='valid',\n",
        "                   activation='relu'))\n",
        "\n",
        "  # Max Pooling Layer #2\n",
        "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 0.25^2 * w, num_filt_1 * num_filt_2]\n",
        "  model.add(MaxPooling1D(pool_size=pool_size_2, \n",
        "                         strides=pool_strides_2, \n",
        "                         padding='valid'))\n",
        "\n",
        "  # Flatten tensor into a batch of vectors\n",
        "  # Input Tensor Shape: [batch_size, 0.25^2 * w, num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 0.25^2 * w * num_filt_1 * num_filt_2]\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Dense Layer (Output layer)\n",
        "  # Densely connected layer with 1024 neurons\n",
        "  # Input Tensor Shape: [batch_size, 0.25^2 * w * num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 1024]\n",
        "  model.add(Dense(units=num_nrn_dl, activation='relu'))  \n",
        "\n",
        "  # Dropout\n",
        "  # Prevents overfitting in deep neural networks\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  # Output layer\n",
        "  # Input Tensor Shape: [batch_size, 1024]\n",
        "  # Output Tensor Shape: [batch_size, p_w]\n",
        "  model.add(Dense(units=num_nrn_ol))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M9XljPR9lnu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "4cec70e9-f7d8-4e5c-a68e-9dbf0b0a8b83"
      },
      "source": [
        "                \"\"\"Configure model\"\"\"\n",
        "sgd = keras.optimizers.SGD(lr=learning_rate, \n",
        "                           decay=1e-6, \n",
        "                           momentum=0.9, \n",
        "                           nesterov=True)\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='mean_absolute_error', \n",
        "              metrics=['accuracy']) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4bcbffe1690c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m      \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      nesterov=True)\n\u001b[0;32m----> 6\u001b[0;31m model.compile(optimizer='sgd', \n\u001b[0m\u001b[1;32m      7\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               metrics=['accuracy']) \n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRoXQxaqgXZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                    \"\"\"Training\"\"\"\n",
        "# Train the model\n",
        "model.fit(\n",
        "  train_seqs,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URqDB0oxhX_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                    \"\"\"Testing\"\"\"\n",
        "# Returns the loss value & metrics values for the model in test mode\n",
        "model.evaluate(\n",
        "    test_seq,\n",
        "    to_categorical(test_labels)\n",
        ") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK0_Cq-Oh0tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                  \"\"\"Save Weights\"\"\"\n",
        "# save it to disk so we can load it back up anytime\n",
        "model.save_weights('model.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzknk4th9bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                   \"\"\"Predicting\"\"\"\n",
        "# Build model \n",
        "DeepAnT_model_generator()\n",
        "          \n",
        "# Load the model's saved weights.\n",
        "model.load_weights('model.h5')\n",
        "          \n",
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_seqs[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(ground_truth_seqs[:5]) # [7, 2, 1, 0, 4]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpCyEz7QqJiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                \"\"\"Anomaly detector\"\"\"\n",
        "def anomaly_detector(prediction_seq, ground_truth_seq)\n",
        "  # calculate Euclidean between actual seq and predicted seq\n",
        "  dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
        "  if (dist > anm_det_thr)\n",
        "    return true  # anomaly\n",
        "  else\n",
        "    return false # normal "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}