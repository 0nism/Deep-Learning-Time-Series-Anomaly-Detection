{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swlee23/Deep-Learning-Time-Series-Anomaly-Detection/blob/master/DeepAnT_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJssM9Hd_rHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Things to be included\n",
        "# 0. preprocess segment for seq (raw -> input format)\n",
        "# 1. visualization tools for sgd\n",
        "# 2. visualization tools for plotting actual and predicted sequence, and anomaly points\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60oNtF4FWakJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d65e44e6-0a7f-45bc-ecc5-b9deb1063f18"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Activation\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1LKB0GwtQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCvn51nkpuah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "              \"\"\"Hyperparameters\"\"\"\n",
        "\n",
        "w = 5                    # History window (length of chopped sequences) / kernel size       \n",
        "p_w = 1                  # Prediction window (number of time stampes required to be \n",
        "                         # predicted)\n",
        "\n",
        "num_filt_1 = 32          # Number of filters in first conv layer\n",
        "num_filt_2 = 32          # Number of filters in second conv layer\n",
        "num_nrn_dl = 40          # Number of neurons in dense layer\n",
        "num_nrn_ol = p_w         # Number of neurons in output layer\n",
        "\n",
        "conv_strides = 1\n",
        "pool_size_1 = 2          # Length of window of pooling layer 1\n",
        "pool_size_2 = 2          # Length of window of pooling layer 2\n",
        "pool_strides_1 = 2       # Stride of window of pooling layer 1\n",
        "pool_strides_2 = 2       # Stride of window of pooling layer 2\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 30          # Daily current trend data for 1 month \n",
        "dropout_rate = 0.5       # Dropout rate in the fully connected layer\n",
        "learning_rate = 2e-5  \n",
        "anm_det_thr = 0.8        # Threshold for classifying anomaly (0.5~0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLBqHZLmomSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8e9b1e91-08e3-48cb-c6ec-13f918c2cf03"
      },
      "source": [
        "              \"\"\"Generate model for DeepAnT\"\"\"\n",
        "def DeepAnT_model_generator():\n",
        "  model = Sequential()\n",
        "  # Input Layer\n",
        "  # Reshape X to 3-D tensor: [batch_size, width, channels]\n",
        "  # MNIST images are 28x28 pixels, and have one color channel\n",
        "\n",
        "\n",
        "  # Convolutional Layer #1\n",
        "  # Computes 32 features using a 1D filter(kernel) of with w with ReLU activation. \n",
        "  # Padding is added to preserve width.\n",
        "  # Input Tensor Shape: [batch_size, input_seq_len, 1]\n",
        "  # Output Tensor Shape: [batch_size, w, num_filt_1] (num_filt_1 = 32 feature vectors)\n",
        "  model.add(Conv1D(filters=num_filt_1,\n",
        "                   kernel_size=w,\n",
        "                   strides=conv_strides,\n",
        "                   padding='valid',\n",
        "                   activation='relu')\n",
        "\n",
        "  # Pooling Layer #1\n",
        "  # First max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, w, num_filt_1]\n",
        "  # Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1]\n",
        "  model.add(MaxPooling1D(pool_size=pool_size_1, \n",
        "                         strides=pool_strides_1, \n",
        "                         padding='valid')\n",
        "\n",
        "  # Convolutional Layer #2\n",
        "  # Computes 64 features using a 5x5 filter.\n",
        "  # Padding is added to preserve width and height.\n",
        "  # Input Tensor Shape: [batch_size, 0.25 * w, 32]\n",
        "  # Output Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "  model.add(Conv1D(filters=num_filt_2,\n",
        "                   kernel_size=w,\n",
        "                   strides=conv_strides,\n",
        "                   padding='valid'\n",
        "                   activation='relu')\n",
        "\n",
        "  # Max Pooling Layer #2\n",
        "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
        "  # Input Tensor Shape: [batch_size, 0.25 * w, num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 0.25^2 * w, num_filt_1 * num_filt_2]\n",
        "  model.add(MaxPooling1D(pool_size=pool_size_2, \n",
        "                         strides=pool_strides_2, \n",
        "                         padding='valid')\n",
        "\n",
        "  # Flatten tensor into a batch of vectors\n",
        "  # Input Tensor Shape: [batch_size, 0.25^2 * w, num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 0.25^2 * w * num_filt_1 * num_filt_2]\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Dense Layer (Output layer)\n",
        "  # Densely connected layer with 1024 neurons\n",
        "  # Input Tensor Shape: [batch_size, 0.25^2 * w * num_filt_1 * num_filt_2]\n",
        "  # Output Tensor Shape: [batch_size, 1024]\n",
        "  model.add(Dense(units=num_nrn_dl, activation='relu')  \n",
        "\n",
        "  # Dropout\n",
        "  # Prevents overfitting in deep neural networks\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  # Output layer\n",
        "  # Input Tensor Shape: [batch_size, 1024]\n",
        "  # Output Tensor Shape: [batch_size, p_w]\n",
        "  model.add(Dense(units=num_nrn_ol, activation='relu')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a20ff1ec053d>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    model.add(MaxPooling1D(pool_size=pool_size_1,\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M9XljPR9lnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                \"\"\"Configure model\"\"\"\n",
        "sgd = optimizers.SGD(lr=learning_rate, \n",
        "                     decay=1e-6, \n",
        "                     momentum=0.9, \n",
        "                     nesterov=True)\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='mean_absolute_error', \n",
        "              metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRoXQxaqgXZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                    \"\"\"Training\"\"\"\n",
        "# Train the model\n",
        "model.fit(\n",
        "  train_seqs,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URqDB0oxhX_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                    \"\"\"Testing\"\"\"\n",
        "# Returns the loss value & metrics values for the model in test mode\n",
        "model.evaluate(\n",
        "    test_seq,\n",
        "    to_categorical(test_labels)\n",
        ") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK0_Cq-Oh0tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                  \"\"\"Save Weights\"\"\"\n",
        "# save it to disk so we can load it back up anytime\n",
        "model.save_weights('model.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzknk4th9bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                   \"\"\"Predicting\"\"\"\n",
        "# Build model \n",
        "DeepAnT_model_generator()\n",
        "          \n",
        "# Load the model's saved weights.\n",
        "model.load_weights('model.h5')\n",
        "          \n",
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_seqs[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(ground_truth_seqs[:5]) # [7, 2, 1, 0, 4]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpCyEz7QqJiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                \"\"\"Anomaly detector\"\"\"\n",
        "def anomaly_detector(prediction_seq, ground_truth_seq)\n",
        "  # calculate Euclidean between actual seq and predicted seq\n",
        "  dist = np.linalg.norm(ground_truth_seq - prediction_seq)  \n",
        "  if (dist > anm_det_thr)\n",
        "    return true  # anomaly\n",
        "  else\n",
        "    return false # normal "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}